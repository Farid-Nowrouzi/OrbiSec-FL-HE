"""
run_week10_utility_tradeoffs.py

Week-10: Utility trade-off plots across modes (from Week-5 run logs).

What this script does (report-safe):
- Reads per-round CSV logs produced by Week-5: results_{mode}.csv
  (these are generated by run_week5_compare_modes.py)
- Computes clean summary stats per mode:
    * final accuracy (last round)
    * mean accuracy (across rounds)
    * mean round_time (sec)
    * mean bytes_up (uplink bytes per round)
    * mean bytes_down (downlink bytes per round)  [optional plot]
- Produces:
    (1) Scatter: Accuracy vs Round Time
    (2) Scatter: Accuracy vs Uplink Bytes
    (3) Bars: Mean Round Time
    (4) Bars: Mean Uplink Bytes
    (5) A compact summary CSV for week-10 utility section

No fabrication:
- If a CSV is missing or a metric column is missing, that mode stays NaN and
  plots that require it will skip that mode automatically.
"""

from __future__ import annotations

from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt


# ---------------------------------------------------------------------
# Paths
# ---------------------------------------------------------------------
THIS_FILE = Path(__file__).resolve()
PROJECT_ROOT = THIS_FILE.parents[1]          # experiments/ -> project root
RESULTS_DIR = PROJECT_ROOT / "results"
RESULTS_DIR.mkdir(parents=True, exist_ok=True)


# ---------------------------------------------------------------------
# Modes (order for report)
# ---------------------------------------------------------------------
MODE_ORDER = ["none", "mask", "secagg", "ckks"]


# ---------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------
def _find_first_existing(paths: List[Path]) -> Optional[Path]:
    for p in paths:
        if p.exists() and p.is_file():
            return p
    return None


def _read_csv_safe(path: Path) -> pd.DataFrame:
    try:
        return pd.read_csv(path)
    except Exception:
        # fallback: try ';'
        return pd.read_csv(path, sep=";")


def _pick_column(df: pd.DataFrame, names: List[str]) -> Optional[str]:
    """
    Pick the first column that matches (case-insensitive) any name in `names`,
    or contains it as substring.
    """
    cols = list(df.columns)
    cols_lower = [c.lower() for c in cols]

    # exact match first
    for n in names:
        nl = n.lower()
        if nl in cols_lower:
            return cols[cols_lower.index(nl)]

    # contains match
    for i, c in enumerate(cols_lower):
        for n in names:
            if n.lower() in c:
                return cols[i]

    return None


def _coerce_numeric(s: pd.Series) -> pd.Series:
    """Robust numeric coercion (handles strings, NaNs, etc.)."""
    if pd.api.types.is_numeric_dtype(s):
        return pd.to_numeric(s, errors="coerce")
    s = s.astype("string")
    s = s.replace({"NA": pd.NA, "N/A": pd.NA, "nan": pd.NA, "None": pd.NA, "": pd.NA})
    s = s.str.replace(",", "", regex=False)
    # handle "x +/- y" and "x±y"
    s = s.str.replace("±", "+/-", regex=False)
    first = s.str.split("+/-", n=1, regex=False).str[0].str.strip()
    return pd.to_numeric(first, errors="coerce")


def _mean_std(vals: pd.Series) -> Tuple[float, float, int]:
    v = _coerce_numeric(vals).dropna()
    if len(v) == 0:
        return float("nan"), float("nan"), 0
    mean = float(v.mean())
    std = float(v.std(ddof=1) if len(v) > 1 else 0.0)
    return mean, std, int(len(v))


def _candidate_csvs_for_mode(mode: str) -> List[Path]:
    """
    Week-5 logs are typically:
      results_none.csv, results_mask.csv, results_secagg.csv, results_ckks.csv
    """
    return [
        RESULTS_DIR / f"results_{mode}.csv",
        RESULTS_DIR / f"week5_results_{mode}.csv",
        RESULTS_DIR / f"week10_{mode}.csv",
        RESULTS_DIR / f"week10_{mode}_results.csv",
        ]


def load_mode_summary(mode: str) -> Dict[str, object]:
    """
    Load one mode's Week-5 log and compute summary stats needed for utility plots.
    """
    out: Dict[str, object] = {
        "mode": mode,
        "source_csv": "",

        "final_acc": np.nan,
        "mean_acc": np.nan,
        "mean_acc_std": np.nan,
        "mean_acc_n": 0,

        "mean_round_time": np.nan,
        "mean_round_time_std": np.nan,
        "mean_round_time_n": 0,

        "mean_bytes_up": np.nan,
        "mean_bytes_up_std": np.nan,
        "mean_bytes_up_n": 0,

        "mean_bytes_down": np.nan,
        "mean_bytes_down_std": np.nan,
        "mean_bytes_down_n": 0,

        "note": "",
    }

    csv_path = _find_first_existing(_candidate_csvs_for_mode(mode))
    if csv_path is None:
        out["note"] = "missing_source_csv"
        return out

    out["source_csv"] = str(csv_path)
    df = _read_csv_safe(csv_path)

    # Required columns (from your server.py logger):
    # round, acc, bytes_up, bytes_down, round_time, agg_time, ...
    acc_col = _pick_column(df, ["acc", "accuracy", "val_acc", "val_accuracy"])
    round_time_col = _pick_column(df, ["round_time", "round_time_s", "round_time_sec"])
    bytes_up_col = _pick_column(df, ["bytes_up", "uplink", "uplink_bytes"])
    bytes_down_col = _pick_column(df, ["bytes_down", "downlink", "downlink_bytes"])

    if acc_col is not None:
        acc_numeric = _coerce_numeric(df[acc_col])
        if acc_numeric.dropna().empty:
            out["note"] += f"|acc_no_numeric({acc_col})"
        else:
            out["final_acc"] = float(acc_numeric.dropna().iloc[-1])
            m, s, n = _mean_std(df[acc_col])
            out["mean_acc"], out["mean_acc_std"], out["mean_acc_n"] = m, s, n
    else:
        out["note"] += "|acc_col_missing"

    if round_time_col is not None:
        m, s, n = _mean_std(df[round_time_col])
        out["mean_round_time"], out["mean_round_time_std"], out["mean_round_time_n"] = m, s, n
    else:
        out["note"] += "|round_time_col_missing"

    if bytes_up_col is not None:
        m, s, n = _mean_std(df[bytes_up_col])
        out["mean_bytes_up"], out["mean_bytes_up_std"], out["mean_bytes_up_n"] = m, s, n
    else:
        out["note"] += "|bytes_up_col_missing"

    if bytes_down_col is not None:
        m, s, n = _mean_std(df[bytes_down_col])
        out["mean_bytes_down"], out["mean_bytes_down_std"], out["mean_bytes_down_n"] = m, s, n
    else:
        out["note"] += "|bytes_down_col_missing"

    return out


# ---------------------------------------------------------------------
# Plotting
# ---------------------------------------------------------------------
def _save_fig(path: Path) -> None:
    plt.tight_layout()
    plt.savefig(path, dpi=180, bbox_inches="tight", pad_inches=0.35)
    plt.close()
    print(f"[Week-10] Saved: {path}")


def plot_scatter(df: pd.DataFrame, x: str, y: str, out: Path, title: str, xlabel: str, ylabel: str) -> None:
    d = df.copy()
    d = d[np.isfinite(d[x].values) & np.isfinite(d[y].values)]
    if len(d) == 0:
        print(f"[Week-10] WARN: Not enough data for scatter '{title}' (missing {x} or {y}).")
        return

    plt.figure(figsize=(9.2, 5.4))
    plt.scatter(d[x].values.astype(float), d[y].values.astype(float))

    # padding (avoid label clipping)
    x_vals = d[x].values.astype(float)
    y_vals = d[y].values.astype(float)
    x_min, x_max = float(np.min(x_vals)), float(np.max(x_vals))
    y_min, y_max = float(np.min(y_vals)), float(np.max(y_vals))
    x_span = (x_max - x_min) if x_max > x_min else (abs(x_max) if x_max != 0 else 1.0)
    y_span = (y_max - y_min) if y_max > y_min else (abs(y_max) if y_max != 0 else 1.0)
    plt.xlim(x_min - 0.12 * x_span, x_max + 0.28 * x_span)
    plt.ylim(y_min - 0.12 * y_span, y_max + 0.12 * y_span)

    for xi, yi, label in zip(x_vals, y_vals, d["mode"].tolist()):
        plt.annotate(label, (xi, yi), textcoords="offset points", xytext=(10, 7), ha="left", fontsize=10)

    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(title)
    plt.grid(True, alpha=0.25)
    _save_fig(out)


def plot_bars(df: pd.DataFrame, col: str, std_col: str, out: Path, title: str, ylabel: str) -> None:
    d = df.copy()
    d = d[np.isfinite(d[col].values)]
    if len(d) == 0:
        print(f"[Week-10] WARN: Not enough data for bars '{title}' (missing {col}).")
        return

    plt.figure(figsize=(9.2, 5.0))
    x = np.arange(len(d))
    means = d[col].values.astype(float)
    stds = d[std_col].values.astype(float) if std_col in d.columns else np.zeros_like(means)

    plt.bar(x, means, yerr=stds, capsize=5)
    plt.xticks(x, d["mode"].tolist())
    plt.ylabel(ylabel)
    plt.title(title)
    plt.grid(True, axis="y", alpha=0.25)

    for xi, yi in zip(x, means):
        plt.text(xi, yi, f"{yi:.4g}", ha="center", va="bottom", fontsize=9)

    _save_fig(out)


# ---------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------
def main() -> None:
    print("[Week-10] Building utility trade-off summary from Week-5 logs...")

    rows = [load_mode_summary(m) for m in MODE_ORDER]
    df = pd.DataFrame(rows)

    # save summary
    out_csv = RESULTS_DIR / "week10_utility_tradeoffs_summary.csv"
    df.to_csv(out_csv, index=False)
    print(f"[Week-10] Wrote: {out_csv}")

    # --- Plots (report-friendly) ---
    # Trade-off: FINAL accuracy vs mean round time
    plot_scatter(
        df=df,
        x="mean_round_time",
        y="final_acc",
        out=RESULTS_DIR / "week10_tradeoff_finalacc_vs_time.png",
        title="Week-10 Utility Trade-off: Final Accuracy vs Mean Round Time",
        xlabel="Mean round time (sec) — lower is better",
        ylabel="Final accuracy — higher is better",
    )

    # Trade-off: FINAL accuracy vs mean uplink bytes
    plot_scatter(
        df=df,
        x="mean_bytes_up",
        y="final_acc",
        out=RESULTS_DIR / "week10_tradeoff_finalacc_vs_uplink.png",
        title="Week-10 Utility Trade-off: Final Accuracy vs Mean Uplink Bytes",
        xlabel="Mean uplink bytes per round — lower is better",
        ylabel="Final accuracy — higher is better",
    )

    # Cost bars: time
    plot_bars(
        df=df,
        col="mean_round_time",
        std_col="mean_round_time_std",
        out=RESULTS_DIR / "week10_cost_bars_round_time.png",
        title="Week-10 Cost Comparison: Mean Round Time",
        ylabel="Mean round time (sec) — lower is better",
    )

    # Cost bars: uplink bytes
    plot_bars(
        df=df,
        col="mean_bytes_up",
        std_col="mean_bytes_up_std",
        out=RESULTS_DIR / "week10_cost_bars_uplink.png",
        title="Week-10 Cost Comparison: Mean Uplink Bytes",
        ylabel="Mean uplink bytes per round — lower is better",
    )

    # Optional: downlink bars (useful sometimes)
    plot_bars(
        df=df,
        col="mean_bytes_down",
        std_col="mean_bytes_down_std",
        out=RESULTS_DIR / "week10_cost_bars_downlink.png",
        title="Week-10 Cost Comparison: Mean Downlink Bytes",
        ylabel="Mean downlink bytes per round — lower is better",
    )

    print("\n[Week-10] Utility trade-offs done. Summary:")
    show_cols = [
        "mode", "final_acc", "mean_acc", "mean_round_time", "mean_bytes_up", "mean_bytes_down", "note", "source_csv"
    ]
    existing = [c for c in show_cols if c in df.columns]
    print(df[existing].to_string(index=False))


if __name__ == "__main__":
    main()
